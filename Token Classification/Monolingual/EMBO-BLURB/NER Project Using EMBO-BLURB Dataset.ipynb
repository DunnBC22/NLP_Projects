{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monolingual Named Entity Recognition (BC2GM-IOB [EMBO-BLURB] Dataset)\n",
    "\n",
    "Dataset Source: https://huggingface.co/datasets/EMBO/BLURB"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install transformers datasets evaluate seqeval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git LFS initialized.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "os.environ['TOKENIZERS_PARALLELISM']='false'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "import evaluate\n",
    "\n",
    "!git lfs install"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display Library Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Python : 3.9.12\n",
      "           NumPy : 1.24.3\n",
      "          Pandas : 2.0.1\n",
      "           Torch : 2.0.0\n",
      "    Transformers : 4.28.1\n",
      "        Datasets : 2.11.0\n",
      "        Evaluate : 0.4.0\n",
      "         Sklearn : 1.2.2\n"
     ]
    }
   ],
   "source": [
    "print(\"Python :\".rjust(18), sys.version[0:6])\n",
    "print(\"NumPy :\".rjust(18), np.__version__)\n",
    "print(\"Pandas :\".rjust(18), pd.__version__)\n",
    "print(\"Torch :\".rjust(18), torch.__version__)\n",
    "print(\"Transformers :\".rjust(18), transformers.__version__)\n",
    "print(\"Datasets :\".rjust(18), datasets.__version__)\n",
    "print(\"Evaluate :\".rjust(18), evaluate.__version__)\n",
    "print(\"Sklearn :\".rjust(18), sklearn.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingest English Subset of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset blurb (/Users/briandunn/.cache/huggingface/datasets/EMBO___blurb/BC2GM-IOB/1.0.0/c9736b8ffc197d4eb4f0b33fdea18902cede876fba559bbdb3dca05abf0042bc)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396d3af6cee943b4a068899d1adbd25f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 12575\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 2520\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 5039\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset(\"EMBO/BLURB\", \"BC2GM-IOB\")\n",
    "\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '12',\n",
       " 'tokens': ['Suppressors',\n",
       "  'of',\n",
       "  'defective',\n",
       "  'silencing',\n",
       "  'in',\n",
       "  'yeast',\n",
       "  ':',\n",
       "  'effects',\n",
       "  'on',\n",
       "  'transcriptional',\n",
       "  'repression',\n",
       "  'at',\n",
       "  'the',\n",
       "  'HMR',\n",
       "  'locus',\n",
       "  ',',\n",
       "  'cell',\n",
       "  'growth',\n",
       "  'and',\n",
       "  'telomere',\n",
       "  'structure',\n",
       "  '.'],\n",
       " 'ner_tags': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = data['train'][12]\n",
    "\n",
    "example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display Feature Information About Each Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: \n",
      "Value(dtype='string', id=None)\n",
      "\n",
      "tokens: \n",
      "Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n",
      "\n",
      "ner_tags: \n",
      "Sequence(feature=ClassLabel(names=['O', 'B-GENE', 'I-GENE'], id=None), length=-1, id=None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in data[\"train\"].features.items():\n",
    "    print(f\"{k}: \\n{v}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Tag Values & Conversions Between String & Integer Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of tag values: \n",
      "['O', 'B-GENE', 'I-GENE']\n",
      "Number of NER Tags: \n",
      "3\n",
      "id2label: \n",
      "{0: 'O', 1: 'B-GENE', 2: 'I-GENE'}\n",
      "label2id: \n",
      "{'O': 0, 'B-GENE': 1, 'I-GENE': 2}\n"
     ]
    }
   ],
   "source": [
    "tag_values = data['train'].features[f'ner_tags'].feature.names\n",
    "NUM_OF_LABELS = len(tag_values)\n",
    "\n",
    "label2id = {tag: idx for idx, tag in enumerate(tag_values)}\n",
    "id2label = {idx: tag for idx, tag in enumerate(tag_values)}\n",
    "\n",
    "print(f\"List of tag values: \\n{tag_values}\")\n",
    "print(f\"Number of NER Tags: \\n{NUM_OF_LABELS}\")\n",
    "print(f\"id2label: \\n{id2label}\")\n",
    "print(f\"label2id: \\n{label2id}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Values/Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CKPT = \"bert-base-cased\"\n",
    "\n",
    "MODEL_NAME = f\"{MODEL_CKPT}-finetuned-ner-BC2GM-IOB\"\n",
    "NUM_OF_EPOCHS = 3\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "STRATEGY = \"epoch\"\n",
    "\n",
    "REPORTS_TO = \"tensorboard\"\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "LR = 2e-5\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "STEPS = 70"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to Tokenize & Align Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CKPT)\n",
    "\n",
    "def tokenize_and_align_labels(samples):\n",
    "    tokenized_inputs = tokenizer(samples[\"tokens\"], \n",
    "                                      truncation=True, \n",
    "                                      is_split_into_words=True)\n",
    "    \n",
    "    labels = []\n",
    "    \n",
    "    for idx, label in enumerate(samples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=idx)\n",
    "        prev_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids: # set special tokens to -100\n",
    "            if word_idx is None or word_idx == prev_word_idx:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(label[word_idx])\n",
    "            prev_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    \n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Above Function to Tokenize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/briandunn/.cache/huggingface/datasets/EMBO___blurb/BC2GM-IOB/1.0.0/c9736b8ffc197d4eb4f0b33fdea18902cede876fba559bbdb3dca05abf0042bc/cache-b08ad379c771f5c4.arrow\n",
      "Loading cached processed dataset at /Users/briandunn/.cache/huggingface/datasets/EMBO___blurb/BC2GM-IOB/1.0.0/c9736b8ffc197d4eb4f0b33fdea18902cede876fba559bbdb3dca05abf0042bc/cache-bee7281f43506a95.arrow\n",
      "Loading cached processed dataset at /Users/briandunn/.cache/huggingface/datasets/EMBO___blurb/BC2GM-IOB/1.0.0/c9736b8ffc197d4eb4f0b33fdea18902cede876fba559bbdb3dca05abf0042bc/cache-b35644c6a806bd61.arrow\n"
     ]
    }
   ],
   "source": [
    "encoded_ds = data.map(tokenize_and_align_labels, \n",
    "                       batched=True, \n",
    "                       remove_columns=\n",
    "                        [\n",
    "                            'ner_tags', \n",
    "                            'tokens'\n",
    "                        ]\n",
    "                    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = (AutoModelForTokenClassification.from_pretrained(\n",
    "    MODEL_CKPT,\n",
    "    num_labels=NUM_OF_LABELS,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    "    ).to(DEVICE))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Compute Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = tag_values\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "labels = [label_list[i] for i in example[f'ner_tags']]\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    predictions, labels = eval_preds\n",
    "    predictions = np.argmax(predictions, \n",
    "                            axis=2)\n",
    "    \n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    results = seqeval.compute(predictions=true_predictions, \n",
    "                              references=true_labels)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    MODEL_NAME,\n",
    "    log_level=\"error\",\n",
    "    logging_first_step=True,\n",
    "    learning_rate=LR,\n",
    "    num_train_epochs=NUM_OF_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    evaluation_strategy=STRATEGY,\n",
    "    report_to=REPORTS_TO,\n",
    "    disable_tqdm=False,\n",
    "    logging_steps=STEPS,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    save_strategy=STRATEGY,\n",
    "    hub_private_repo=True,\n",
    "    push_to_hub=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/DunnBC22/bert-base-cased-finetuned-ner-BC2GM-IOB into local empty directory.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, \n",
    "                  args=args,\n",
    "                  data_collator=data_collator,\n",
    "                  compute_metrics=compute_metrics,\n",
    "                  tokenizer=tokenizer,\n",
    "                  train_dataset=encoded_ds[\"train\"],\n",
    "                  eval_dataset=encoded_ds[\"test\"]\n",
    "                  )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/briandunn/Documents/deep_learning/dl/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d86f44be9ec44c89dee801ddbc7348d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2358 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2403, 'learning_rate': 1.9991518235793047e-05, 'epoch': 0.0}\n",
      "{'loss': 0.2543, 'learning_rate': 1.9406276505513148e-05, 'epoch': 0.09}\n",
      "{'loss': 0.1402, 'learning_rate': 1.8812553011026297e-05, 'epoch': 0.18}\n",
      "{'loss': 0.1295, 'learning_rate': 1.8218829516539443e-05, 'epoch': 0.27}\n",
      "{'loss': 0.1082, 'learning_rate': 1.762510602205259e-05, 'epoch': 0.36}\n",
      "{'loss': 0.1081, 'learning_rate': 1.7031382527565735e-05, 'epoch': 0.45}\n",
      "{'loss': 0.1021, 'learning_rate': 1.643765903307888e-05, 'epoch': 0.53}\n",
      "{'loss': 0.0958, 'learning_rate': 1.5843935538592027e-05, 'epoch': 0.62}\n",
      "{'loss': 0.0876, 'learning_rate': 1.5250212044105175e-05, 'epoch': 0.71}\n",
      "{'loss': 0.0886, 'learning_rate': 1.4656488549618322e-05, 'epoch': 0.8}\n",
      "{'loss': 0.0822, 'learning_rate': 1.4062765055131468e-05, 'epoch': 0.89}\n",
      "{'loss': 0.0882, 'learning_rate': 1.3469041560644616e-05, 'epoch': 0.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d154c45f8f4ae48d9c72c913b9cac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/315 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07710690796375275, 'eval_GENE': {'precision': 0.7383090740167234, 'recall': 0.7538339920948617, 'f1': 0.7459907689900649, 'number': 6325}, 'eval_overall_precision': 0.7383090740167234, 'eval_overall_recall': 0.7538339920948617, 'eval_overall_f1': 0.7459907689900649, 'eval_overall_accuracy': 0.9697417488586066, 'eval_runtime': 557.7788, 'eval_samples_per_second': 9.034, 'eval_steps_per_second': 0.565, 'epoch': 1.0}\n",
      "{'loss': 0.0723, 'learning_rate': 1.2875318066157762e-05, 'epoch': 1.07}\n",
      "{'loss': 0.0614, 'learning_rate': 1.228159457167091e-05, 'epoch': 1.16}\n",
      "{'loss': 0.0601, 'learning_rate': 1.1687871077184054e-05, 'epoch': 1.25}\n",
      "{'loss': 0.0641, 'learning_rate': 1.1094147582697202e-05, 'epoch': 1.34}\n",
      "{'loss': 0.0568, 'learning_rate': 1.0500424088210348e-05, 'epoch': 1.42}\n",
      "{'loss': 0.0558, 'learning_rate': 9.906700593723495e-06, 'epoch': 1.51}\n",
      "{'loss': 0.0565, 'learning_rate': 9.312977099236641e-06, 'epoch': 1.6}\n",
      "{'loss': 0.0653, 'learning_rate': 8.719253604749789e-06, 'epoch': 1.69}\n",
      "{'loss': 0.0597, 'learning_rate': 8.125530110262937e-06, 'epoch': 1.78}\n",
      "{'loss': 0.0547, 'learning_rate': 7.531806615776082e-06, 'epoch': 1.87}\n",
      "{'loss': 0.0547, 'learning_rate': 6.9380831212892285e-06, 'epoch': 1.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfbee8150d3f4b3b947663f1965724e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/315 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0823470875620842, 'eval_GENE': {'precision': 0.7617199627444893, 'recall': 0.7758102766798419, 'f1': 0.76870055612125, 'number': 6325}, 'eval_overall_precision': 0.7617199627444893, 'eval_overall_recall': 0.7758102766798419, 'eval_overall_f1': 0.76870055612125, 'eval_overall_accuracy': 0.9731502457045272, 'eval_runtime': 530.7254, 'eval_samples_per_second': 9.495, 'eval_steps_per_second': 0.594, 'epoch': 2.0}\n",
      "{'loss': 0.0431, 'learning_rate': 6.344359626802375e-06, 'epoch': 2.05}\n",
      "{'loss': 0.036, 'learning_rate': 5.750636132315522e-06, 'epoch': 2.14}\n",
      "{'loss': 0.0386, 'learning_rate': 5.156912637828668e-06, 'epoch': 2.23}\n",
      "{'loss': 0.0411, 'learning_rate': 4.563189143341816e-06, 'epoch': 2.32}\n",
      "{'loss': 0.0382, 'learning_rate': 3.969465648854962e-06, 'epoch': 2.4}\n",
      "{'loss': 0.0407, 'learning_rate': 3.375742154368109e-06, 'epoch': 2.49}\n",
      "{'loss': 0.0344, 'learning_rate': 2.7820186598812554e-06, 'epoch': 2.58}\n",
      "{'loss': 0.0411, 'learning_rate': 2.1882951653944023e-06, 'epoch': 2.67}\n",
      "{'loss': 0.0354, 'learning_rate': 1.594571670907549e-06, 'epoch': 2.76}\n",
      "{'loss': 0.0359, 'learning_rate': 1.0008481764206957e-06, 'epoch': 2.85}\n",
      "{'loss': 0.0356, 'learning_rate': 4.071246819338423e-07, 'epoch': 2.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f856e30e4e854063894c24db674d3801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/315 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08134816586971283, 'eval_GENE': {'precision': 0.752111423914654, 'recall': 0.8025296442687747, 'f1': 0.7765029830197338, 'number': 6325}, 'eval_overall_precision': 0.752111423914654, 'eval_overall_recall': 0.8025296442687747, 'eval_overall_f1': 0.7765029830197338, 'eval_overall_accuracy': 0.9736102882236085, 'eval_runtime': 517.72, 'eval_samples_per_second': 9.733, 'eval_steps_per_second': 0.608, 'epoch': 3.0}\n",
      "{'train_runtime': 14396.5104, 'train_samples_per_second': 2.62, 'train_steps_per_second': 0.164, 'train_loss': 0.07137536916619544, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "train_results = trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Push Model To Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7aa1954287d4178ac74026a40525470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/411M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89fb33d9015e4803a68163f237f297bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file runs/Jul04_13-53-48_Brians-Mac-mini.local/events.out.tfevents.1688496833.Brians-Mac-mini.local.148…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/DunnBC22/bert-base-cased-finetuned-ner-BC2GM-IOB\n",
      "   9348d66..66868d7  main -> main\n",
      "\n",
      "To https://huggingface.co/DunnBC22/bert-base-cased-finetuned-ner-BC2GM-IOB\n",
      "   66868d7..472a033  main -> main\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\n",
    "    \"tasks\": \"token-classification\",\n",
    "    \"tags\": ['token-classification'],\n",
    "}\n",
    "\n",
    "if args.push_to_hub:\n",
    "    trainer.push_to_hub('All DUNN!!!', **kwargs)\n",
    "else:\n",
    "    trainer.create_model_card(**kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save & Log Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/DunnBC22/bert-base-cased-finetuned-ner-BC2GM-IOB\n",
      "   472a033..e35f7e0  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =        3.0\n",
      "  train_loss               =     0.0714\n",
      "  train_runtime            = 3:59:56.51\n",
      "  train_samples_per_second =       2.62\n",
      "  train_steps_per_second   =      0.164\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Method to Apply to Validation Dataset (& Then Apply it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass_with_label(batch):\n",
    "    # Convert dict of lists to list of dicts suitable for data collator\n",
    "    features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n",
    "    # Pad inputs and labels and put all tensors on device\n",
    "    batch = data_collator(features)\n",
    "    input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "    attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "    labels = batch[\"labels\"].to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        # Pass data through model  \n",
    "        output = trainer.model(input_ids, \n",
    "                               attention_mask\n",
    "                               )\n",
    "        # Logit.size: [batch_size, sequence_length, classes]\n",
    "        predicted_label = torch.argmax(output.logits, \n",
    "                                       axis=-1\n",
    "                                       ).cpu().numpy()\n",
    "        \n",
    "    # Calculate loss per token after flattening batch dimension with view\n",
    "    loss = cross_entropy(output.logits.view(-1, 3), \n",
    "                         labels.view(-1), \n",
    "                         reduction=\"none\")\n",
    "    # Unflatten batch dimension and convert to numpy array\n",
    "    loss = loss.view(len(input_ids), -1).cpu().numpy()\n",
    "\n",
    "    return {\"loss\":loss, \"predicted_label\": predicted_label}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Above Function to Entire Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function forward_pass_with_label at 0x7fef780ac430> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd1bd3abcd1d4af7bb83d58ab4e401f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_set = encoded_ds['validation']\n",
    "\n",
    "eval_set = eval_set.remove_columns('id')\n",
    "\n",
    "eval_set = eval_set.map(forward_pass_with_label,\n",
    "                        batched=True,\n",
    "                        batch_size=32)\n",
    "\n",
    "eval_df = eval_set.to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Up Padding Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[101, 10768, 1116, 1105, 143, 119, 102]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[IGN, O, IGN, O, O, O, IGN]</td>\n",
       "      <td>[0.0, 0.00050329417, 0.0, 0.00033539868, 0.000...</td>\n",
       "      <td>[O, O, O, O, O, O, O]</td>\n",
       "      <td>[[CLS], Joy, ##s, and, F, ., [SEP]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 input_ids         token_type_ids   \n",
       "0  [101, 10768, 1116, 1105, 143, 119, 102]  [0, 0, 0, 0, 0, 0, 0]  \\\n",
       "\n",
       "          attention_mask                       labels   \n",
       "0  [1, 1, 1, 1, 1, 1, 1]  [IGN, O, IGN, O, O, O, IGN]  \\\n",
       "\n",
       "                                                loss        predicted_label   \n",
       "0  [0.0, 0.00050329417, 0.0, 0.00033539868, 0.000...  [O, O, O, O, O, O, O]  \\\n",
       "\n",
       "                          input_tokens  \n",
       "0  [[CLS], Joy, ##s, and, F, ., [SEP]]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label[-100] = \"IGN\"\n",
    "eval_df[\"input_tokens\"] = eval_df[\"input_ids\"].apply(\n",
    "    lambda x: tokenizer.convert_ids_to_tokens(x))\n",
    "eval_df[\"predicted_label\"] = eval_df[\"predicted_label\"].apply(\n",
    "    lambda x: [id2label[i] for i in x])\n",
    "eval_df[\"labels\"] = eval_df[\"labels\"].apply(\n",
    "    lambda x: [id2label[i] for i in x])\n",
    "eval_df['loss'] = eval_df.apply(\n",
    "    lambda x: x['loss'][:len(x['input_ids'])], axis=1)\n",
    "eval_df['predicted_label'] = eval_df.apply(\n",
    "    lambda x: x['predicted_label'][:len(x['input_ids'])], axis=1)\n",
    "eval_df.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unwrap Each Token Within Sample Separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10768</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>O</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1105</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>O</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>O</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>O</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>O</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2740</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>O</td>\n",
       "      <td>cases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1104</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.0</td>\n",
       "      <td>O</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  input_ids token_type_ids attention_mask labels  loss predicted_label   \n",
       "0     10768              0              1      O   0.0               O  \\\n",
       "0      1105              0              1      O   0.0               O   \n",
       "0       143              0              1      O   0.0               O   \n",
       "0       119              0              1      O   0.0               O   \n",
       "1       123              0              1      O   0.0               O   \n",
       "1      2740              0              1      O   0.0               O   \n",
       "1      1104              0              1      O   0.0               O   \n",
       "\n",
       "  input_tokens  \n",
       "0          Joy  \n",
       "0          and  \n",
       "0            F  \n",
       "0            .  \n",
       "1            2  \n",
       "1        cases  \n",
       "1           of  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df_tokens = eval_df.apply(pd.Series.explode)\n",
    "eval_df_tokens = eval_df_tokens.query(\"labels != 'IGN'\")\n",
    "eval_df_tokens[\"loss\"] = eval_df_tokens[\"loss\"].astype(float).round(2)\n",
    "eval_df_tokens.head(7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See Which Tokens Have Accumulated Most Loss in Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>input_tokens</th>\n",
       "      <td>-</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>c</td>\n",
       "      <td>(</td>\n",
       "      <td>)</td>\n",
       "      <td>and</td>\n",
       "      <td>p</td>\n",
       "      <td>1</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2618</td>\n",
       "      <td>286</td>\n",
       "      <td>205</td>\n",
       "      <td>346</td>\n",
       "      <td>1038</td>\n",
       "      <td>1055</td>\n",
       "      <td>1797</td>\n",
       "      <td>532</td>\n",
       "      <td>399</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.204</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>534.28</td>\n",
       "      <td>90.49</td>\n",
       "      <td>90.09</td>\n",
       "      <td>85.35</td>\n",
       "      <td>84.98</td>\n",
       "      <td>84.98</td>\n",
       "      <td>81.27</td>\n",
       "      <td>78.88</td>\n",
       "      <td>74.23</td>\n",
       "      <td>74.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0      1      2      3      4      5      6      7      8   \n",
       "input_tokens       -      C      E      c      (      )    and      p      1  \\\n",
       "count           2618    286    205    346   1038   1055   1797    532    399   \n",
       "mean           0.204  0.316  0.439  0.247  0.082  0.081  0.045  0.148  0.186   \n",
       "sum           534.28  90.49  90.09  85.35  84.98  84.98  81.27  78.88  74.23   \n",
       "\n",
       "                  9  \n",
       "input_tokens      T  \n",
       "count           279  \n",
       "mean          0.266  \n",
       "sum           74.22  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    eval_df_tokens.groupby(\"input_tokens\")[[\"loss\"]]\n",
    "    .agg([\"count\", \"mean\", \"sum\"])\n",
    "    .droplevel(level=0, axis=1) # Get rid of multi-level columns\n",
    "    .sort_values(by=\"sum\", ascending=False)\n",
    "    .reset_index()\n",
    "    .round(3)\n",
    "    .head(10)\n",
    "    .T\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See Which Label IDs Have Most Loss in Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>I-GENE</td>\n",
       "      <td>B-GENE</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4437</td>\n",
       "      <td>3061</td>\n",
       "      <td>63544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.458</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>2030.86</td>\n",
       "      <td>1046.26</td>\n",
       "      <td>2471.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0        1        2\n",
       "labels   I-GENE   B-GENE        O\n",
       "count      4437     3061    63544\n",
       "mean      0.458    0.342    0.039\n",
       "sum     2030.86  1046.26  2471.79"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    eval_df_tokens.groupby(\"labels\")[[\"loss\"]] \n",
    "    .agg([\"count\", \"mean\", \"sum\"])\n",
    "    .droplevel(level=0, axis=1) # Get rid of multi-level columns\n",
    "    .sort_values(by=\"mean\", ascending=False)\n",
    "    .reset_index()\n",
    "    .round(3)\n",
    "    .fillna(0)\n",
    "    .T\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Function to Display Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "    plt.title(\"Normalized confusion matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_token_list = list(set(eval_df_tokens['labels']))\n",
    "\n",
    "plot_confusion_matrix(eval_df_tokens[\"labels\"], eval_df_tokens[\"predicted_label\"],\n",
    "                      eval_token_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes & Other Takeaways From This Project\n",
    "\n",
    "****\n",
    "- The trend of the model over predictingO and B-GENE as I-GENE continues into this model.\n",
    "\n",
    "****"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citations\n",
    "\n",
    "- Model Checkpoint\n",
    "\n",
    "    > @article{DBLP:journals/corr/abs-1810-04805, author = {Jacob Devlin and Ming{-}Wei Chang and Kenton Lee and Kristina Toutanova}, title = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language Understanding}, journal = {CoRR}, volume = {abs/1810.04805}, year = {2018}, url = {http://arxiv.org/abs/1810.04805}, archivePrefix = {arXiv}, eprint = {1810.04805}, timestamp = {Tue, 30 Oct 2018 20:39:56 +0100}, biburl = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib}, bibsource = {dblp computer science bibliography, https://dblp.org}}\n",
    "\n",
    "- Dataset\n",
    "\n",
    "    >  @article{article, author = {Smith, Larry and Tanabe, Lorraine and Ando, Rie and Kuo, Cheng-Ju and Chung, I-Fang and Hsu, Chun-Nan and Lin, Yu-Shi and Klinger, Roman and Friedrich, Christoph and Ganchev, Kuzman and Torii, Manabu and Liu, Hongfang and Haddow, Barry and Struble, Craig and Povinelli, Richard and Vlachos, Andreas and Baumgartner Jr, William and Hunter, Lawrence and Carpenter, Bob and Wilbur, W.}, year = {2008}, month = {09}, pages = {S2}, title = {Overview of BioCreative II gene mention recognition}, volume = {9 Suppl 2}, journal = {Genome biology}, doi = {10.1186/gb-2008-9-s2-s2}}\n",
    "\n",
    "- Metric (SeqEval)\n",
    "\n",
    "    > @inproceedings{ramshaw-marcus-1995-text, title = \"Text Chunking using Transformation-Based Learning\", author = \"Ramshaw, Lance and Marcus, Mitch\", booktitle = \"Third Workshop on Very Large Corpora\", year = \"1995\", url = \"https://www.aclweb.org/anthology/W95-0107\",}\n",
    "    \n",
    "    > @misc{seqeval, title={{seqeval}: A Python framework for sequence labeling evaluation}, url={https://github.com/chakki-works/seqeval}, note={Software available from https://github.com/chakki-works/seqeval}, author={Hiroki Nakayama}, year={2018},}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
