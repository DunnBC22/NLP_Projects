{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer Prediction Dataset: Question & Answering\n",
    "\n",
    "Dataset Source: https://www.kaggle.com/datasets/a2m2a2n2/question-answer-dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git LFS initialized.\n"
     ]
    }
   ],
   "source": [
    "import os, sys, random, collections, ast\n",
    "os.environ['TOKENIZERS_PARALLELISM']='false'\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset, Dataset, DatasetDict, ClassLabel, Sequence\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, set_seed\n",
    "from transformers import TrainingArguments, Trainer, default_data_collator\n",
    "\n",
    "import torch\n",
    "\n",
    "import evaluate\n",
    "\n",
    "!git lfs install"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display Library Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Python: 3.9.7 \n",
      "         NumPy: 1.23.3\n",
      "      Datasets: 2.8.0\n",
      "  Transformers: 4.26.1\n",
      "      Evaluate: 0.2.2\n",
      "         Torch: 1.12.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Python:\".rjust(15), sys.version[0:6])\n",
    "print(\"NumPy:\".rjust(15), np.__version__)\n",
    "print(\"Datasets:\".rjust(15), datasets.__version__)\n",
    "print(\"Transformers:\".rjust(15), transformers.__version__)\n",
    "print(\"Evaluate:\".rjust(15), evaluate.__version__)\n",
    "print(\"Torch:\".rjust(15), torch.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & Start Processing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50125 entries, 0 to 74856\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   context   50125 non-null  object\n",
      " 1   question  50125 non-null  object\n",
      " 2   answers   50125 non-null  object\n",
      " 3   id        50125 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "parent_dir = \"/Users/leedunn/Desktop/Projects_to_Train/Object Detection\"\n",
    "\n",
    "data = pd.read_csv(os.path.join(parent_dir, \"Question_Answer.csv\"))\n",
    "\n",
    "# only keep samples which has answers\n",
    "data = data[data[\"Answer_possible\"] == True]\n",
    "\n",
    "# Rename Features as needed\n",
    "data.rename(columns={\n",
    "    \"Answer_start\": \"answer_start\", \n",
    "    \"Answer_text\": \"answer_text\",\n",
    "    \"Question\": \"question\",\n",
    "    \"Paragraph\" : \"context\"\n",
    "    }, inplace=True)\n",
    "\n",
    "# Remove unnecessary Features\n",
    "data.drop(columns=[\"Theme\", \"Answer_possible\"], inplace=True)\n",
    "\n",
    "# Concatenate the Answer_text & Answer_start into a dictionary in column named \"answer\"\n",
    "data[\"answers\"] =  \"{\\\"text\\\": \" + data[\"answer_text\"] + \", \\\"answer_start\\\": \" + data[\"answer_start\"] + \"}\"\n",
    "\n",
    "data[\"answers\"] = data[\"answers\"].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "data.drop(columns=[\"answer_text\", \"answer_start\"], inplace=True)\n",
    "\n",
    "data['id'] = data.index.astype(str)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: The current administration presides over an uneasy internal peace and faces difficult economic problems of stimulating recovery and reducing poverty, despite record-high oil prices since 2003. Natural gas and diamonds are also recent major Congolese exports, although Congo was excluded from the Kimberley Process in 2004 amid allegations that most of its diamond exports were in fact being smuggled out of the neighboring Democratic Republic of Congo; it was re-admitted to the group in 2007.\n",
      "\n",
      "Question: When was the Congo allowed back into the Kimberley Process?\n"
     ]
    }
   ],
   "source": [
    "n = 5000\n",
    "print(f\"Context: {data['context'][n]}\")\n",
    "print(f\"\\nQuestion: {data['question'][n]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual: Histogram of Input Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "para_n_question = pd.DataFrame()\n",
    "para_n_question[\"input\"] = data[\"context\"] + data[\"question\"]\n",
    "para_n_question[\"input_len\"] = para_n_question['input'].str.split().str.len()\n",
    "max(para_n_question[\"input_len\"])\n",
    "\n",
    "para_n_question.hist('input_len', grid=False, bins=60, figsize=(18,8))\n",
    "plt.suptitle('')\n",
    "plt.title('Histogram of Input Length')\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Words per Input')\n",
    "plt.show()\n",
    "\n",
    "para_n_question.drop(columns=[\"input\", \"input_len\"], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert DataFrame to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', 'question', 'answers', 'id', '__index_level_0__'],\n",
       "    num_rows: 50125\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(data)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Dataset into Training & Evaluation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (40100, 5)\n",
      "Evaluation data shape: (10025, 5)\n",
      "{'context': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'answers': {'answer_start': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'text': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}, 'id': Value(dtype='string', id=None), '__index_level_0__': Value(dtype='int64', id=None)}\n"
     ]
    }
   ],
   "source": [
    "train_testvalid = dataset.train_test_split(test_size=0.20)\n",
    "\n",
    "ds = DatasetDict({\n",
    "    'train' : train_testvalid['train'],\n",
    "    'eval' : train_testvalid['test']\n",
    "})\n",
    "\n",
    "print('Training data shape:', ds['train'].shape)\n",
    "print('Evaluation data shape:', ds['eval'].shape)\n",
    "print(ds['train'].features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Values/Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CKPT = \"bert-base-uncased\"\n",
    "MODEL_NAME = MODEL_CKPT.split(\"/\")[-1] + \"-question_and_answer\"\n",
    "\n",
    "MAX_LENGTH = 384\n",
    "DOC_STRIDE = 128\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "set_seed(42)\n",
    "\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_OF_EPOCH = 3\n",
    "\n",
    "WEIGHT_DECAY = 0.01"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to Preprocess Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e847ed63ae43e4b7eaf4586fcfe7e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcfd2c7c6a984acb8e0e572d4060e019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76b47f223a648999af2597f5cd90871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64762d4a336e47e18cfaa1531e36a6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CKPT)\n",
    "\n",
    "def preprocess_training_ds(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples['context'],\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=\"only_second\",\n",
    "        stride=DOC_STRIDE,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    \n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]\n",
    "        answer = answers[sample_idx]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start & end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label is (0, 0)\n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Else it is the start & end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Training Preprocessing Function to Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "819e537699314823a67ccf4175e8eab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(40100, 40554)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = ds[\"train\"].map(\n",
    "    preprocess_training_ds,\n",
    "    batched=True,\n",
    "    remove_columns=ds[\"train\"].column_names,\n",
    ")\n",
    "\n",
    "len(ds[\"train\"]), len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_validation_ds(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=\"only_second\",\n",
    "        stride=DOC_STRIDE,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    example_ids = []\n",
    "\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_idx = sample_map[i]\n",
    "        example_ids.append(examples[\"id\"][sample_idx])\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "        ]\n",
    "\n",
    "    inputs[\"example_id\"] = example_ids\n",
    "    return inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Preprocessing Function to Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b996c4328f1453080ea99c5b435b368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10025, 10113)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_ds = ds[\"eval\"].map(\n",
    "    preprocess_validation_ds,\n",
    "    batched=True,\n",
    "    remove_columns=ds[\"eval\"].column_names,\n",
    ")\n",
    "len(ds[\"eval\"]), len(eval_ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Function to Evaluate Model (Compute Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "721fb43420964e508d70aba967bb18f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c3be329358f4f1e9eee47704bec876c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = evaluate.load(\"squad\")\n",
    "n_best = 20\n",
    "max_answer_length = 30\n",
    "\n",
    "def compute_metrics(start_logits, end_logits, features, examples):\n",
    "    example_to_features = collections.defaultdict(list)\n",
    "    for idx, feature in enumerate(features):\n",
    "        example_to_features[feature[\"example_id\"]].append(idx)\n",
    "\n",
    "    predicted_answers = []\n",
    "    for example in tqdm(examples):\n",
    "        example_id = example[\"id\"]\n",
    "        context = example[\"context\"]\n",
    "        answers = []\n",
    "\n",
    "        # Loop through all features associated with that example\n",
    "        for feature_index in example_to_features[example_id]:\n",
    "            start_logit = start_logits[feature_index]\n",
    "            end_logit = end_logits[feature_index]\n",
    "            offsets = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # Skip answers that are not fully in the context\n",
    "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                        continue\n",
    "                    # Skip answers with a length that is either < 0 or > max_answer_length\n",
    "                    if (\n",
    "                        end_index < start_index\n",
    "                        or end_index - start_index + 1 > max_answer_length\n",
    "                    ):\n",
    "                        continue\n",
    "\n",
    "                    answer = {\n",
    "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
    "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
    "                    }\n",
    "                    answers.append(answer)\n",
    "\n",
    "        # Select the answer with the best score\n",
    "        if len(answers) > 0:\n",
    "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "            predicted_answers.append(\n",
    "                {\"id\": example_id, \"prediction_text\": best_answer[\"text\"]}\n",
    "            )\n",
    "        else:\n",
    "            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n",
    "\n",
    "    theoretical_answers = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples]\n",
    "    return metric.compute(predictions=predicted_answers, references=theoretical_answers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2f7b407fad4f44a0782dd5b7f59d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(MODEL_CKPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    MODEL_NAME,\n",
    "    evaluation_strategy=\"no\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_train_epochs=NUM_OF_EPOCH,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    push_to_hub=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/DunnBC22/bert-base-uncased-question_and_answer into local empty directory.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leedunn/Documents/nlpnn/nlp/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 40554\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15210\n",
      "  Number of trainable parameters = 108893186\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c092cd5dcd9348b3b0b03f523c744b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9395, 'learning_rate': 1.9342537804076265e-05, 'epoch': 0.1}\n",
      "{'loss': 1.7226, 'learning_rate': 1.8685075608152533e-05, 'epoch': 0.2}\n",
      "{'loss': 1.4624, 'learning_rate': 1.80276134122288e-05, 'epoch': 0.3}\n",
      "{'loss': 1.4056, 'learning_rate': 1.7370151216305063e-05, 'epoch': 0.39}\n",
      "{'loss': 1.3203, 'learning_rate': 1.671268902038133e-05, 'epoch': 0.49}\n",
      "{'loss': 1.2649, 'learning_rate': 1.6055226824457594e-05, 'epoch': 0.59}\n",
      "{'loss': 1.2347, 'learning_rate': 1.539776462853386e-05, 'epoch': 0.69}\n",
      "{'loss': 1.2236, 'learning_rate': 1.4740302432610125e-05, 'epoch': 0.79}\n",
      "{'loss': 1.1746, 'learning_rate': 1.4082840236686392e-05, 'epoch': 0.89}\n",
      "{'loss': 1.2067, 'learning_rate': 1.3425378040762658e-05, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to bert-base-uncased-question_and_answer/checkpoint-5070\n",
      "Configuration saved in bert-base-uncased-question_and_answer/checkpoint-5070/config.json\n",
      "Model weights saved in bert-base-uncased-question_and_answer/checkpoint-5070/pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-question_and_answer/checkpoint-5070/tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-question_and_answer/checkpoint-5070/special_tokens_map.json\n",
      "tokenizer config file saved in bert-base-uncased-question_and_answer/tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-question_and_answer/special_tokens_map.json\n",
      "Adding files tracked by Git LFS: ['.DS_Store']. This may take a bit of time if the files are large.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8849, 'learning_rate': 1.2767915844838923e-05, 'epoch': 1.08}\n",
      "{'loss': 0.7939, 'learning_rate': 1.2110453648915189e-05, 'epoch': 1.18}\n",
      "{'loss': 0.8559, 'learning_rate': 1.1452991452991454e-05, 'epoch': 1.28}\n",
      "{'loss': 0.8442, 'learning_rate': 1.0795529257067721e-05, 'epoch': 1.38}\n",
      "{'loss': 0.83, 'learning_rate': 1.0138067061143987e-05, 'epoch': 1.48}\n",
      "{'loss': 0.8227, 'learning_rate': 9.48060486522025e-06, 'epoch': 1.58}\n",
      "{'loss': 0.8064, 'learning_rate': 8.823142669296516e-06, 'epoch': 1.68}\n",
      "{'loss': 0.7891, 'learning_rate': 8.165680473372781e-06, 'epoch': 1.78}\n",
      "{'loss': 0.8144, 'learning_rate': 7.508218277449047e-06, 'epoch': 1.87}\n",
      "{'loss': 0.8424, 'learning_rate': 6.850756081525313e-06, 'epoch': 1.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to bert-base-uncased-question_and_answer/checkpoint-10140\n",
      "Configuration saved in bert-base-uncased-question_and_answer/checkpoint-10140/config.json\n",
      "Model weights saved in bert-base-uncased-question_and_answer/checkpoint-10140/pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-question_and_answer/checkpoint-10140/tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-question_and_answer/checkpoint-10140/special_tokens_map.json\n",
      "tokenizer config file saved in bert-base-uncased-question_and_answer/tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-question_and_answer/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6021, 'learning_rate': 6.193293885601579e-06, 'epoch': 2.07}\n",
      "{'loss': 0.5701, 'learning_rate': 5.535831689677844e-06, 'epoch': 2.17}\n",
      "{'loss': 0.5489, 'learning_rate': 4.878369493754109e-06, 'epoch': 2.27}\n",
      "{'loss': 0.5363, 'learning_rate': 4.220907297830375e-06, 'epoch': 2.37}\n",
      "{'loss': 0.5821, 'learning_rate': 3.563445101906641e-06, 'epoch': 2.47}\n",
      "{'loss': 0.5356, 'learning_rate': 2.9059829059829063e-06, 'epoch': 2.56}\n",
      "{'loss': 0.5635, 'learning_rate': 2.2485207100591717e-06, 'epoch': 2.66}\n",
      "{'loss': 0.5553, 'learning_rate': 1.5910585141354374e-06, 'epoch': 2.76}\n",
      "{'loss': 0.5547, 'learning_rate': 9.335963182117029e-07, 'epoch': 2.86}\n",
      "{'loss': 0.5155, 'learning_rate': 2.7613412228796843e-07, 'epoch': 2.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to bert-base-uncased-question_and_answer/checkpoint-15210\n",
      "Configuration saved in bert-base-uncased-question_and_answer/checkpoint-15210/config.json\n",
      "Model weights saved in bert-base-uncased-question_and_answer/checkpoint-15210/pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-question_and_answer/checkpoint-15210/tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-question_and_answer/checkpoint-15210/special_tokens_map.json\n",
      "tokenizer config file saved in bert-base-uncased-question_and_answer/tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-question_and_answer/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 532317.3501, 'train_samples_per_second': 0.229, 'train_steps_per_second': 0.029, 'train_loss': 0.9549857636802217, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15210, training_loss=0.9549857636802217, metrics={'train_runtime': 532317.3501, 'train_samples_per_second': 0.229, 'train_steps_per_second': 0.029, 'train_loss': 0.9549857636802217, 'epoch': 3.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute & Display Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id. If offset_mapping, example_id are not expected by `BertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 10113\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19de7c2b2823407bba85064822be597a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec36ea433433420c8eae87802e691f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10025 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'exact_match': 65.7356608478803, 'f1': 79.28347788592988}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, _, _ = trainer.predict(eval_ds)\n",
    "start_logits, end_logits = predictions\n",
    "compute_metrics(start_logits, end_logits, eval_ds, ds[\"eval\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Push Model to Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to bert-base-uncased-question_and_answer\n",
      "Configuration saved in bert-base-uncased-question_and_answer/config.json\n",
      "Model weights saved in bert-base-uncased-question_and_answer/pytorch_model.bin\n",
      "tokenizer config file saved in bert-base-uncased-question_and_answer/tokenizer_config.json\n",
      "Special tokens file saved in bert-base-uncased-question_and_answer/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f125bc92c9ec40fc9efc24b667900096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file runs/Feb28_13-10-33_Lees-Air/events.out.tfevents.1677611439.Lees-Air.8335.0: 100%|##########| 8.71…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "remote: Scanning LFS files of refs/heads/main for validity...        \n",
      "remote: LFS file scan complete.        \n",
      "To https://huggingface.co/DunnBC22/bert-base-uncased-question_and_answer\n",
      "   f10f78f..13ce860  main -> main\n",
      "\n",
      "Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Question Answering', 'type': 'question-answering'}}\n",
      "To https://huggingface.co/DunnBC22/bert-base-uncased-question_and_answer\n",
      "   13ce860..b704d7a  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/DunnBC22/bert-base-uncased-question_and_answer/commit/13ce860448e69412d6a88c866d7d7d67ad99f311'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(commit_message=\"All DUNN!!!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes & Other Takeaways\n",
    "****\n",
    "- This model turned out better than I expected.\n",
    "****"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citations\n",
    "- Model Checkpoint\n",
    "    - @article{DBLP:journals/corr/abs-1810-04805,\n",
    "  author    = {Jacob Devlin and\n",
    "               Ming{-}Wei Chang and\n",
    "               Kenton Lee and\n",
    "               Kristina Toutanova},\n",
    "  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language\n",
    "               Understanding},\n",
    "  journal   = {CoRR},\n",
    "  volume    = {abs/1810.04805},\n",
    "  year      = {2018},\n",
    "  url       = {http://arxiv.org/abs/1810.04805},\n",
    "  archivePrefix = {arXiv},\n",
    "  eprint    = {1810.04805},\n",
    "  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},\n",
    "  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},\n",
    "  bibsource = {dblp computer science bibliography, https://dblp.org}\n",
    "}\n",
    "****\n",
    "- Metric (SQuAD)\n",
    "  - @inproceedings{Rajpurkar2016SQuAD10,\n",
    "title={SQuAD: 100, 000+ Questions for Machine Comprehension of Text},\n",
    "author={Pranav Rajpurkar and Jian Zhang and Konstantin Lopyrev and Percy Liang},\n",
    "booktitle={EMNLP},\n",
    "year={2016}\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "41bc52750e0704433c7c40a5c68d8f60e760babe95f2dffc82e8c3790208ff57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
